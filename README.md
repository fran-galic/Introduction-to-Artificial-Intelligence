# Introduction to Artificial Intelligence â€” Laboratory Exercises (FER, 2024/2025)

This repository contains solutions for the laboratory exercises in the course *Introduction to Artificial Intelligence* at FER, academic year 2024/2025.  
The course covered fundamental AI methods, from symbolic reasoning to machine learning, with a strong emphasis on practical implementation.

---

## Lab 1: State Space Search

The first lab focused on solving problems using **state space search algorithms**.  
Implemented algorithms include:
- **Breadth-First Search (BFS)**, **Uniform Cost Search (UCS)**, and **A\***  
- General loading and representation of state spaces and heuristic functions  
- Evaluation of heuristics for **optimism** and **consistency**

The algorithms were applied to problems such as route finding on maps and solving the sliding puzzle.  
This lab highlighted the importance of search strategies and heuristic quality in solving complex problems efficiently.

---

## Lab 2: Automated Reasoning with Resolution

The second lab introduced **automated reasoning** through the **resolution refutation method**.  
Key components:
- Implementation of a resolution-based inference engine capable of proving or disproving clauses using strategies like set of support and clause simplification  
- Development of a **cooking assistant expert system**, with recipes and ingredients modeled as logical clauses  

The system could answer queries about whether a dish could be prepared, as well as update the knowledge base dynamically.  
The lab demonstrated how logic-based reasoning can be applied in practice.

---

## Lab 3: Decision Trees

The third lab centered on **decision tree learning** using the **ID3 algorithm**.  
Main tasks:
- Training decision trees with information gain as the splitting criterion  
- Predicting outcomes on unseen datasets  
- Evaluating models with **accuracy** and **confusion matrix**  
- Introducing tree depth as a hyperparameter to reduce overfitting and improve generalization  

This exercise provided insight into the trade-offs between model complexity and performance.

---

## Lab 4: Neural Networks with Genetic Algorithms

The final lab combined **neural networks** with **genetic algorithms** for optimization.  
Tasks included:
- Implementing feed-forward neural networks with different architectures (e.g., 5s, 20s, 5s5s)  
- Using genetic algorithms to optimize network weights, with operators such as elitism, crossover, mutation, and fitness-proportional selection  
- Approximating functions including the sinusoidal curve, Rosenbrock function, and Rastrigin function  
- Measuring performance using **mean squared error (MSE)** on training and test sets  

This lab demonstrated an alternative to backpropagation for training neural networks, showing how evolutionary methods can effectively explore parameter spaces.

---
